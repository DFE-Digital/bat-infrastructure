groups:
- name: High CPU
  rules:
%{ for app_name, app_config in apps ~}
  - alert: High-CPU-${app_name}
    expr: avg by ( app ) (cpu{app=~"${app_name}"}) > 50
    for: 5m
    annotations:
      summary:     ${app_name} High CPU Alert
      dashboard:   ${grafana_dashboard_url}&var-Applications=${app_name}
      description: "CPU usage has increased in the last 5 minutes (current value: {{ $value }}%)"
    labels:
      environment: production
      severity:    high
      app:         ${app_name}
%{ endfor ~}

- name: Memory Utilisation
  rules:
%{ for app_name, app_config in apps ~}
  - alert: High-Memory-Utilisation-${app_name}
    expr: avg by ( app ) (memory_utilization{app=~"${app_name}"}) > 60
    for: 5m
    annotations:
      summary:     ${app_name} high memory utilization
      dashboard:   ${grafana_dashboard_url}&var-Applications=${app_name}
      description: "Memory utilization has increased in the last 5 minutes (current value: {{ $value }}%)"
    labels:
      severity:    high
      app:         ${app_name}
      environment: production
%{ endfor ~}

- name: Disk Utilisation
  rules:
%{ for app_name, app_config in apps ~}
  - alert: High-Disk-Utilisation-${app_name}
    expr: avg by ( app ) ( disk_utilization{ app=~"${app_name}" }) > 60
    for: 5m
    annotations:
      summary:     ${app_name} high disk utilization
      dashboard:   ${grafana_dashboard_url}&var-Applications=${app_name}
      description: "Disk utilization has increased in the last 5 minutes (current value: {{ $value }})%"
    labels:
      severity:    high
      app:         ${app_name}
      environment: production
%{ endfor ~}

- name: App Crashes
  rules:
%{ for app_name, app_config in apps ~}
  - alert: App-Crash-${app_name}
    expr: rate(crash{app=~"${app_name}"}[1m])*60 > 1
    for: 5m
    annotations:
      summary:     At least one instance of ${app_name} has crashed in the last 5 mins
      dashboard:   ${grafana_dashboard_url}&var-Applications=${app_name}
      description: At least one instance of ${app_name} has crashed in the last 5 mins
    labels:
      severity:    high
      app:         ${app_name}
      environment: production
%{ endfor ~}

- name: Elevated Request Failures
  rules:
%{ for app_name, app_config in apps ~}
  - alert: Request-Failures-${app_name}
    expr:  sum(rate(requests{app="${app_name}", status_range=~"0xx|4xx|5xx"}[5m]))*60 > 25
    for: 5m
    annotations:
      summary:     Failed requests count
      dashboard:   ${grafana_dashboard_url}&var-Applications=${app_name}
      description: "Number({{ $value }}) of non success status codes too high in the last 5 mins for ${app_name}"
    labels:
      severity:    high
      app:         ${app_name}
      environment: production
%{ endfor ~}

- name: Average Response Time
  rules:
%{ for app_name, app_config in apps ~}
  - alert: Response-Times-${app_name}
    expr:  histogram_quantile(0.95, sum(rate(response_time_bucket{app="${app_name}", status_range="2xx"}[5m])) by (le)) > %{ if app_config.response_threshold == null }1%{ else }${app_config.response_threshold}%{ endif }
    for: 5m
    annotations:
      summary:     Slow running requests
      dashboard:   ${grafana_dashboard_url}&var-Applications=${app_name}
      description: "Requests in the 95 percentile taking longer than %{ if app_config.response_threshold == null }1%{ else }${app_config.response_threshold}%{ endif } seconds (current value: {{ humanize $value}}s )"
    labels:
      severity:    high
      app:         ${app_name}
      environment: production
%{ endfor ~}

- name: Redis Memory Utilisation
  rules:
%{ for redis_instance in alertable_redis_instances ~}
  - alert: Redis memory utilisation high (instance - ${redis_instance})
    expr: (redis_memory_used_bytes{instance=~"${redis_instance}"} / redis_memory_max_bytes{instance=~"${redis_instance}"}) > 0.60
    for: 4m
    annotations:
      summary:     ${redis_instance} high memory utilization
      dashboard:   ${redis_dashboard_url}&var-instance=${redis_instance}.london.cloudapps.digital:443
      description: "Redis Memory utilization is greater than 60% (current value: {{ $value }})"
    labels:
      severity:    high
      app:         ${redis_instance}
      environment: production
%{ endfor ~}

- name: Slow Sidekiq Jobs
  rules:
%{ for app_name, app_config in apps ~}
%{ if app_config.sidekiq_worker_app_names != null }
%{ for worker_app_name in app_config.sidekiq_worker_app_names ~}
  - alert: Slow Sidekiq Runtime (${worker_app_name})
    ##TO DO: revert threshold to 10
    expr: count(max(rate(sidekiq_job_runtime_seconds_sum{app="${worker_app_name}"}[2m])) by (worker) / max(rate(sidekiq_job_runtime_seconds_count{app="${worker_app_name}"}[2m])) by (worker) > 0.2) > 0
    for: 9s
    annotations:
      summary:     Sidekiq job runtime greater than 10 seconds
      dashboard:   ${sidekiq_dashboard_url}&var-Apps=${worker_app_name}
      description: Runtime for ${worker_app_name} sidekiq job(s) in the last 2 minutes 10 seconds or higher
    labels:
      severity:    high
      app:         ${worker_app_name}
      environment: ${monitoring_space_name}
%{ endfor ~}
%{ endif }
%{ endfor ~}
